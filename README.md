# ğŸš€ LLM-Powered Search and Orchestration Playground

ğŸ‘‹ Welcome! This is your go-to playground to explore, experiment, and learn about orchestrating and integrating Large Language Models (LLMs) for search and enrichment applications. Dive in, discover, and create amazing LLM-powered experiences!

## ğŸŒŸ What Does This Project Offer?

- ğŸ“’ **Interactive Notebooks:** Explore retrieval augmented generation (RAG), embedding models, vector stores, prompt engineering, and more!
- ğŸ¨ **Streamlit Application:** A hands-on demo app for LLM-based re-ranking of search results.
- ğŸŒ **Containerized LangGraph Server:** Run and manage advanced LLM orchestration through a dedicated LangGraph server.
- âš™ï¸ **Customizable Environment:** Easily configure your favorite LLM providers and settings.
- ğŸ³ **Docker-Based Setup:** Quick setup to jumpstart your experiments using Docker.

## ğŸ“‚ Project Structure

- **app/**: Streamlit demo (`streamlit_app.py`).
- **src/**: Core utilities and logic.
- **notebooks/**: Interactive Jupyter notebooks covering exciting LLM topics.
- **langgraph/**: Advanced LLM orchestration and agent frameworks.
- **env.dist**: Template for environment variables (copy and customize to `.env`).
- **Dockerfile & docker-compose.yml**: Simple setup for reproducible development.

## ğŸ› ï¸ Prerequisites

- ğŸ³ Docker and Docker Compose installed.
- ğŸ Python 3.11 recommended (if running locally without Docker).

## ğŸš¦ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd llm-search-poc-main
```

### 2ï¸âƒ£ Configure API Keys and Environment

Copy and set up your environment variables:

```bash
cp env.dist .env
```

Edit `.env` with your credentials:

```env
# LLM Providers
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_gemini_key
ANTHROPIC_API_KEY=your_anthropic_key

# Optional APIs
SERPAPI_API_KEY=your_serpapi_key
TAVILY_API_KEY=your_tavily_key

# LangSmith Tracing (optional)
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY=your_langsmith_key
LANGSMITH_PROJECT=llm-playground-yourname
```

âš ï¸ **Important:** Personalize `LANGSMITH_PROJECT` to avoid conflicts!

### 3ï¸âƒ£ Launch Your Playground

Build and start all services:

```bash
docker-compose up -d
```

ğŸš€ Services running:

- ğŸ“š **Jupyter Notebooks:** [http://localhost:8888](http://localhost:8888)
- ğŸ¯ **Streamlit App (Search Re-ranking):** [http://localhost:7777](http://localhost:7777)
- ğŸŒ **LangGraph Server:** [http://localhost:2024](http://localhost:2024) (see below for usage details)

## ğŸ® Using the Streamlit App

Experience LLM-enhanced search re-ranking with:

- **Manual Query Analysis:** Compare baseline results against LLM-ranked results.
- **CSV Bulk Analysis:** Process multiple queries from CSV files.
- **Settings Panel:** Fully customize prompts, providers, models, and temperature settings.

### âš™ï¸ Settings Explained

- âœï¸ **Prompt Templates:** Customize prompts for various ranking methods.
- ğŸ¤– **LLM Providers & Models:** Select your preferred provider and model (OpenAI, Gemini, Anthropic).
- ğŸ² **Temperature:** Adjust the creativity and randomness of model responses.

## ğŸ““ Explore Interactive Notebooks

Visit [http://localhost:8888](http://localhost:8888) to dive deeper into:

- ğŸ’¬ Chat Models
- ğŸ§‘â€ğŸ’» Prompt Engineering
- ğŸ” Retrieval and RAG
- ğŸ—ƒï¸ Embedding Models & Vector Stores
- â€¦and much more!

## ğŸŒ Advanced Usage: Containerized LangGraph Server

Explore powerful orchestration examples under the `langgraph/` directory. The LangGraph server is fully containerized for your convenience:

- **Access the LangGraph Studio UI:**

  [LangGraph Studio](https://smith.langchain.com/studio/?baseUrl=http://localhost:2024)

Ensure you use `localhost` (or your host IP) in the browser URL above to properly connect.

ğŸ§‘â€ğŸš€ **Graph Details:**

- ğŸ› ï¸ **CodeAct Agent:** Dynamically execute Python code via LLM-driven instructionsâ€”ideal for automating tasks and integrating Python logic.
- ğŸŒ± **Data Enrichment Agent:** Automatically enrich and categorize data, extracting insights and structuring information for intelligent workflows.

## ğŸ¤ Contribute and Grow With Us!

We warmly welcome your contributions! Join us by:

- ğŸ“– Adding new notebooks or examples.
- ğŸ› ï¸ Improving current implementations.
- ğŸ Reporting bugs or proposing enhancements.

ğŸ‰ Happy exploring and experimenting with the limitless possibilities of LLM orchestration!