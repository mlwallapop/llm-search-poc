{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§­ Vector Stores\n",
    "\n",
    "Vector stores are specialized databases for **semantic search**. They index embeddingsâ€”numerical representations of your textâ€”to help retrieve relevant content based on **meaning**, not just keywords.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Why Use Vector Stores?\n",
    "\n",
    "- ğŸ“š Search unstructured data like text, images, audio  \n",
    "- ğŸ” Find relevant content using **semantic similarity**  \n",
    "- ğŸ§© Great for building intelligent search and RAG apps\n",
    "\n",
    "![Vector Stores](assets/vectorstores-2540b4bc355b966c99b0f02cfdddb273.png \"Vector store\")\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”Œ Integrations\n",
    "\n",
    "LangChain supports many vectorstore backends. Easily swap providers using a **standard interface**.\n",
    "\n",
    "ğŸ”— [See full list of integrations](https://python.langchain.com/docs/integrations/vectorstores/)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Core Interface Methods\n",
    "\n",
    "- `add_documents`: Add data to the vector store  \n",
    "- `delete`: Remove documents  \n",
    "- `similarity_search`: Retrieve documents similar to a query\n",
    "\n",
    "ğŸ› ï¸ Initialization\n",
    "```python\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embedding=SomeEmbeddingModel())\n",
    "```\n",
    "\n",
    "\n",
    "ğŸ› ï¸ Add Documents:\n",
    "```python\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2]\n",
    "\n",
    "vector_store.add_documents(documents=documents)\n",
    "```\n",
    "\n",
    "\n",
    "ğŸ› ï¸ Delete Documents:\n",
    "```python\n",
    "vector_store.delete(ids=[\"doc1\"])\n",
    "```\n",
    "\n",
    "\n",
    "ğŸ› ï¸ Search:\n",
    "```python\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ How Similarity Works\n",
    "\n",
    "Embeddings = points in space. Compare them using:\n",
    "\n",
    "- ğŸ“ Cosine Similarity  \n",
    "- ğŸ“ Euclidean Distance  \n",
    "- ğŸ¯ Dot Product\n",
    "\n",
    "Choice depends on the vectorstore. Check its docs for supported metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® Under the Hood: Similarity Search\n",
    "\n",
    "Search happens in two steps:\n",
    "\n",
    "1. Embed the query  \n",
    "2. Compare it with document embeddings to find matches\n",
    "\n",
    "Efficient search algorithms like **HNSW** power this under the hood.\n",
    "\n",
    "ğŸ› ï¸ Similarity Search:\n",
    "```python\n",
    "query = \"my query\"\n",
    "docs = vectorstore.similarity_search(query)\n",
    "```\n",
    "\n",
    "Supports `k` (number of docs) and `filter` (metadata filtering) parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§¾ Metadata Filtering\n",
    "\n",
    "Filter results using metadata like source, date, or tags.\n",
    "\n",
    "ğŸ› ï¸ Metadata Filtering:\n",
    "```python\n",
    "vectorstore.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "```\n",
    "ğŸ” Combines semantic + structured search for precision.\n",
    "\n",
    "ğŸ”— [See Pinecone metadata filtering docs](#)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Advanced Search Techniques\n",
    "\n",
    "| **Technique**             | **Use When**                          | **What It Does**                                        |\n",
    "|--------------------------|---------------------------------------|---------------------------------------------------------|\n",
    "| Hybrid Search            | You want **keyword + semantic** match | Merges keyword and vector search for better recall      |\n",
    "| Maximal Marginal Relevance (MMR) | You want **diverse results**         | Reduces redundancy by reranking search results          |\n",
    "\n",
    "ğŸ”— [How-to guide on hybrid search](https://python.langchain.com/docs/how_to/hybrid/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
