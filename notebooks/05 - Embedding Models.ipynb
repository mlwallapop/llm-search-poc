{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Embedding Models\n",
    "\n",
    "Imagine turning any piece of text—tweets, docs, or books—into a compact, machine-readable form. That’s what **embedding models** do! They transform text into numerical vectors that capture meaning, enabling semantic search, ranking, and clustering.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 Key Concepts\n",
    "\n",
    "![Embedding Models](assets/embeddings_concept-975a9aaba52de05b457a1aeff9a7393a.png \"Embedding Models\")\n",
    "\n",
    "1. **Embed text** ➡️ Convert text into a vector (a list of numbers)\n",
    "2. **Compare meaning** ➡️ Use math (like cosine similarity) to compare vectors\n",
    "\n",
    "---\n",
    "\n",
    "## 🕰️ A Quick History\n",
    "\n",
    "- 📌 **BERT (2018)**: Google’s breakthrough for understanding text  \n",
    "- ⚡ **SBERT**: Tuned for sentence embeddings with better speed & accuracy  \n",
    "- 🧪 **MTEB**: A benchmark to compare modern embedding models\n",
    "\n",
    "**Explore more:**\n",
    "- [BERT Paper](#)\n",
    "- [Cameron Wolfe's Review](#)\n",
    "- [MTEB Leaderboard](#)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 LangChain Interface\n",
    "\n",
    "LangChain makes working with embeddings simple:\n",
    "\n",
    "- `embed_documents` → for multiple texts  \n",
    "- `embed_query` → for a single query  \n",
    "\n",
    "🛠️ **Example Placeholder:** _Embed a list of strings_  \n",
    "🔗 Replace with your code snippet: `<<EMBED_DOCUMENTS_EXAMPLE>>`\n",
    "\n",
    "🛠️ **Example Placeholder:** _Embed a query_  \n",
    "🔗 Replace with your code snippet: `<<EMBED_QUERY_EXAMPLE>>`\n",
    "\n",
    "**Learn more:** [Embedding Integrations](#) · [How-to Guides](#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embeddings_model.embed_query(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 📏 Measuring Similarity\n",
    "\n",
    "Embeddings are like coordinates in space. The closer two vectors are, the more semantically related their texts are.\n",
    "\n",
    "### Common Similarity Metrics:\n",
    "\n",
    "- 📐 **Cosine Similarity**: Angle between vectors  \n",
    "- 📍 **Euclidean Distance**: Straight-line distance  \n",
    "- 🎯 **Dot Product**: Projection of one onto another  \n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)\n",
    "```\n",
    "\n",
    "**Suggested by:** OpenAI (for their models)\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Further Reading\n",
    "\n",
    "- [Simon Willison on Embeddings](https://simonwillison.net/2023/Oct/23/embeddings/)  \n",
    "- [Google on Similarity Metrics](https://developers.google.com/machine-learning/clustering/dnn-clustering/supervised-similarity)  \n",
    "- [OpenAI FAQ on Similarity](https://platform.openai.com/docs/guides/embeddings/faq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
