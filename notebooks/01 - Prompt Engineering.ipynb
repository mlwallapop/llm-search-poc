{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide clear instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by generating tutorials given a text.\n",
    "You will be provided with a text. If the text contains any kind of istructions on how to proceed with something, generate a tutorial in a bullet list.\n",
    "Otherwise, inform the user that the text does not contain any instructions.\n",
    "\n",
    "Text: \n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "To prepare the known sauce from Genova, Italy, you can start by toasting the pine nuts to then coarsely \n",
    "chop them in a kitchen mortar together with basil and garlic. Then, add half of the oil in the kitchen mortar and season with salt and pepper.\n",
    "Finally, transfer the pesto to a bowl and stir in the grated Parmesan cheese.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a tutorial on how to prepare the known sauce from Genova, Italy:\n",
      "\n",
      "- Start by toasting the pine nuts.\n",
      "- Coarsely chop the toasted pine nuts in a kitchen mortar together with basil and garlic.\n",
      "- Add half of the oil in the kitchen mortar and season with salt and pepper.\n",
      "- Transfer the pesto to a bowl.\n",
      "- Stir in the grated Parmesan cheese.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": instructions},\n",
    "    ]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.invoke(messages)\n",
    "#print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text does not contain any instructions.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": 'the sun is shining and dogs are running on the beach.'},\n",
    "    ]\n",
    "\n",
    "response = llm.invoke(\n",
    "    messages\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split complext tasks into subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that summarize articles. \n",
    "To complete this task, do the following subtasks:\n",
    "\n",
    "Read the provided article context comprehensively and identified the main topic and key points\n",
    "Generated a paragraph summary of the current article context that captures the essential information and conveys the main idea\n",
    "Print each step of the proces.\n",
    "Article:\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "Recurrent neural networks, long short-term memory and gated recurrent neural networks\n",
    "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
    "transduction problems such as language modeling and machine translation. Numerous\n",
    "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
    "architectures.\n",
    "Recurrent models typically factor computation along the symbol positions of the input and output\n",
    "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
    "states ht, as a function of the previous hidden state ht-1 and the input for position t. This inherently\n",
    "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
    "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
    "significant improvements in computational efficiency through factorization tricks and conditional\n",
    "computation, while also improving model performance in case of the latter. The fundamental\n",
    "constraint of sequential computation, however, remains.\n",
    "Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
    "the input or output sequences. In all but a few cases, however, such attention mechanisms\n",
    "are used in conjunction with a recurrent network.\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
    "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
    "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
    "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Step 1: Main Topic and Key Points Identified\\n- Main Topic: The article discusses the evolution of sequence modeling and transduction problems using recurrent neural networks, particularly focusing on long short-term memory and gated recurrent neural networks.\\n- Key Points:\\n1. Recurrent neural networks, including LSTM and GRNN, are widely used in sequence modeling and transduction tasks like language modeling and machine translation.\\n2. Recurrent models compute hidden states sequentially, limiting parallelization and posing challenges with longer sequences.\\n3. Recent advancements have improved computational efficiency and model performance through factorization tricks and conditional computation.\\n4. Attention mechanisms have enhanced sequence modeling by capturing dependencies regardless of distance in sequences, often combined with recurrent networks.\\n5. The article introduces the Transformer model, which relies solely on attention mechanisms, enabling increased parallelization and achieving state-of-the-art translation quality in a short training time.\\n\\nStep 2: Generated Paragraph Summary\\nThe article delves into the advancements in sequence modeling and transduction problems using recurrent neural networks, specifically long short-term memory and gated recurrent neural networks. It highlights the challenges of sequential computation in recurrent models, the integration of attention mechanisms to address dependencies, and introduces the Transformer model as a novel architecture that relies on attention mechanisms alone, enabling enhanced parallelization and achieving remarkable translation quality with minimal training time.\\n\\nStep 3: Printing the Summary\\nThe summary of the article has been generated successfully.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 405, 'total_tokens': 687, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-894f0e66-daf1-445d-ab1c-f58262f98b42-0' usage_metadata={'input_tokens': 405, 'output_tokens': 282, 'total_tokens': 687, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": article},\n",
    "    ]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in generating essays shorter than 500 words.\n",
    "Given a statement, develop the essay the best you can.\n",
    "Once the essay is generated, provide clear justifications and explanations of the reasons behind the sentences you generated.\n",
    "\n",
    "Statement:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "statement = \"\"\"\n",
    "An introduction to mammals like chickens.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Mammals are a diverse group of animals characterized by features such as having hair or fur, giving birth to live young, and producing milk to feed their offspring. Chickens, however, are not mammals; they belong to the bird group. While both mammals and birds are warm-blooded and have similar metabolic processes, they differ in key characteristics. Mammals, including humans, dogs, and whales, have mammary glands to nurse their young, while birds, like chickens, lay eggs. Understanding the distinctions between mammals and birds, such as chickens, helps us appreciate the vast array of life forms on Earth and the unique adaptations that have evolved in different species.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 70, 'total_tokens': 205, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-88647cd6-ecde-4912-aaad-0b0374b58212-0' usage_metadata={'input_tokens': 70, 'output_tokens': 135, 'total_tokens': 205, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": statement},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, solve it the best you can.\n",
    "Provide a clear justification of your answer and the reasoning behind it.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The answer to the riddle is a clock. \\n\\nA clock has a face with numbers or markings to indicate time, and two hands (hour and minute hands) that move around the face to show the time. A clock does not have arms or legs, which eliminates the possibility of it being a living being or a human. Therefore, a clock fits the description provided in the riddle.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 66, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f53bc622-aa84-47c8-bc14-09ac7d550a35-0' usage_metadata={'input_tokens': 66, 'output_tokens': 80, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate many output - self consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "There are four friends: Alice, Bob, Charlie, and David. They each have a different favorite color: red, blue, green, and yellow. They also each have a different favorite animal: cat, dog, fish, and bird. Using the following clues, can you figure out who likes what color and what animal?\n",
    "\n",
    "Alice does not like red or blue.\n",
    "Bob likes dogs, but not green.\n",
    "Charlie likes fish, but not yellow.\n",
    "David likes yellow, but not cats.\n",
    "The person who likes red also likes birds.\n",
    "The person who likes blue also likes cats.\n",
    "\n",
    "You can write your answer in the form of four sentences, such as “Alice likes green and fish.” \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice likes green and bird.\n",
      "Bob likes yellow and dog.\n",
      "Charlie likes blue and fish.\n",
      "David likes red and cat.\n",
      "\n",
      "Reasoning:\n",
      "- From the clues given, we can deduce that Alice cannot like red or blue, so she must like green. Since the person who likes red also likes birds, Alice must like birds.\n",
      "- Bob likes dogs and not green, so he must like yellow. Charlie likes fish and not yellow, so Charlie must like blue and fish.\n",
      "- David likes yellow and not cats, so he must like red and his favorite animal is cat.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conversation = \"\"\"\n",
    "Customer: Hi, I need some help with my order.\n",
    "AI agent: Hello, welcome to our online store. I'm an AI agent and I'm here to assist you. \n",
    "Customer: I ordered a pair of shoes yesterday, but I haven't received a confirmation email yet. Can you check the status of my order?\n",
    "AI agent: Sure, I can help you with that. Can you please provide me with your order number and email address?\n",
    "Customer: Yes, my order number is 123456789 and my email is john.doe@example.com.\n",
    "AI agent: Thank you. I have found your order in our system. It looks like your order is still being processed and it will be shipped soon. You should receive a confirmation email within 24 hours.\n",
    "Customer: OK, thank you for the information. How long will it take for the shoes to arrive?\n",
    "AI agent: You're welcome. According to our shipping policy, it will take about 3 to 5 business days for the shoes to arrive at your address. You can track your order online using the tracking number that will be sent to your email once your order is shipped.\n",
    "Customer: Alright, sounds good. Thank you for your help.\n",
    "AI agent: It's my pleasure. Is there anything else I can do for you today?\n",
    "Customer: No, that's all. Have a nice day.\n",
    "AI agent: Thank you for choosing our online store. Have a nice day too. Goodbye. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": conversation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "{conversation}\n",
    "\n",
    "Remember to return only the sentiment, in lower cap and without punctuation!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A neutron is a subatomic particle that has a neutral (not positive or negative) charge, and a mass slightly greater than that of a proton. \n",
    "It is present in all atomic nuclei except those of ordinary hydrogen. \n",
    "Neutrons, along with protons and electrons, are one of the three basic particles making up atoms. \n",
    "The term “neutron” comes from the fact that it is electrically neutral, meaning it carries no charge.\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\"\"\"\n",
    "Reframe the text for a 5 years old child. It should be shorter than 500 words. Make a parallelism with animals.\n",
    "\n",
    "The text is the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine neutrons as a special kind of animal that lives inside the homes of other animals called atoms. They are like a friendly neighbor who doesn't have any special powers like being super positive or super negative. They are just right in the middle, like a superhero with a neutral power. Neutrons are always hanging out with their friends, protons, and electrons, who together make up the atoms. Neutrons are called neutrons because they are electrically neutral, which means they don't have any electric charge. Just like how some animals have different colors or sizes, neutrons have their own special trait of being neutral.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a Python expert that produces python code as per user's request.\n",
    "\n",
    "===>START EXAMPLE\n",
    "\n",
    "---User Query---\n",
    "Give me a function to print a string of text.\n",
    "\n",
    "---User Output---\n",
    "Below you can find the described function:\n",
    "```def my_print(text):\n",
    "     return print(text)\n",
    "```\n",
    "<===END EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "query = \"generate a python function to calculate the nth Fibonacci number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below you can find the described function:\n",
      "```\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Invalid input. Please provide a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tal\n",
    "\n",
    "Product name:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation Embrace - Rise to New Heights in Style\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": product_name},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movie.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movie.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd .read_csv('movie.csv', encoding='utf-8')\n",
    "df['label'] = df['label'].replace({0: 'Negative', 1: 'Positive'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>The central theme in this movie seems to be co...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>The ending made my heart jump up into my throa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>Only the chosen ones will appreciate the quali...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>This is a really funny film, especially the se...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "32823  The central theme in this movie seems to be co...  Negative\n",
       "16298  An excellent example of \"cowboy noir\", as it's...  Positive\n",
       "28505  The ending made my heart jump up into my throa...  Negative\n",
       "6689   Only the chosen ones will appreciate the quali...  Positive\n",
       "26893  This is a really funny film, especially the se...  Positive"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=10, random_state=42)  # Change the value of 'random_state' as needed for reproducibility\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a binary classifier for sentiment analysis.\n",
    "Given a text, based on its sentiment you classify it into one of two categories: positive or negative.\n",
    "\n",
    "You can use the following texts as examples:\n",
    "\n",
    "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
    "Positive\n",
    "\n",
    "Text: \"I'm really disappointed with the quality of the food.\"\n",
    "Negative\n",
    "\n",
    "Text: \"This is the best day of my life!\"\n",
    "Positive\n",
    "\n",
    "Text: \"I can't stand the noise in this restaurant.\"\n",
    "Negative\n",
    "\n",
    "ONLY return the sentiment as output (without punctuation).\n",
    "\n",
    "Text:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text = \"The concert was amazing! The band was incredible!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text     label predicted\n",
      "32823  The central theme in this movie seems to be co...  Negative  Negative\n",
      "16298  An excellent example of \"cowboy noir\", as it's...  Positive  Positive\n",
      "28505  The ending made my heart jump up into my throa...  Negative  Positive\n",
      "6689   Only the chosen ones will appreciate the quali...  Positive  Positive\n",
      "26893  This is a really funny film, especially the se...  Positive  Positive\n",
      "36572  Sure, we all like bad movies at one time or an...  Negative  Negative\n",
      "12335  Why?!! This was an insipid, uninspired and emb...  Negative  Negative\n",
      "29591  This is one of those movies that has everythin...  Positive  Positive\n",
      "18948  i saw this film over 20 years ago and still re...  Positive  Positive\n",
      "31067  This true story of Carlson's Raiders is more o...  Negative  Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-3.5-turbo\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "df['predicted'] = df['text'].apply(process_text)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>The central theme in this movie seems to be co...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>The ending made my heart jump up into my throa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>Only the chosen ones will appreciate the quali...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>This is a really funny film, especially the se...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  predicted\n",
       "32823  The central theme in this movie seems to be co...  Negative   Negative\n",
       "16298  An excellent example of \"cowboy noir\", as it's...  Positive  Positive.\n",
       "28505  The ending made my heart jump up into my throa...  Negative   Positive\n",
       "6689   Only the chosen ones will appreciate the quali...  Positive   Positive\n",
       "26893  This is a really funny film, especially the se...  Positive   Positive"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "To solve a generic first-degree equation, follow these steps:\n",
    "\n",
    "1. **Identify the Equation:** Start by identifying the equation you want to solve. It should be in the form of \"ax + b = c,\" where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.\n",
    "\n",
    "2. **Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. To do this, perform the following steps:\n",
    "   \n",
    "   a. **Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.\n",
    "   \n",
    "   b. **Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. If 'a' is zero, the equation may not have a unique solution.\n",
    "\n",
    "3. **Simplify:** Simplify both sides of the equation as much as possible.\n",
    "\n",
    "4. **Solve for 'x':** Once 'x' is isolated on one side, you have the solution. It will be in the form of 'x = value.'\n",
    "\n",
    "5. **Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. If it does, you've found the correct solution.\n",
    "\n",
    "6. **Express the Solution:** Write down the solution in a clear and concise form.\n",
    "\n",
    "7. **Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.\n",
    "\n",
    "\n",
    "Equation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "equation = \"3x + 5 = 11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Identify the Equation: The equation is 3x + 5 = 11.\n",
      "\n",
      "2. Isolate the Variable:\n",
      "   \n",
      "   a. Subtract Constants: Subtract 5 from both sides to move constants to one side: \n",
      "   \n",
      "      3x + 5 - 5 = 11 - 5 \n",
      "   \n",
      "   Simplifying, we get:\n",
      "   \n",
      "      3x = 6\n",
      "   \n",
      "   b. Divide by the Coefficient: Divide both sides by 3 to isolate 'x':\n",
      "   \n",
      "      3x/3 = 6/3\n",
      "   \n",
      "   Simplifying, we get:\n",
      "   \n",
      "      x = 2\n",
      "   \n",
      "3. Simplify: Both sides are already simplified.\n",
      "\n",
      "4. Solve for 'x': x = 2.\n",
      "\n",
      "5. Check Your Solution: Plug x = 2 back into the original equation:\n",
      "\n",
      "   3(2) + 5 = 11\n",
      "   \n",
      "   Simplifying, we get:\n",
      "   \n",
      "   6 + 5 = 11\n",
      "   \n",
      "   The left side equals the right side, so the solution is correct.\n",
      "\n",
      "6. Express the Solution: The solution to the equation 3x + 5 = 11 is x = 2.\n",
      "\n",
      "7. Consider Special Cases: Since the coefficient 3 is not zero, there are no special cases to consider.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": equation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openaivaalt.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"8d236d7c6ed945ddb80358800bd2866c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "# Import Azure OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    deployment_name='gpt-3.5-turbo',\n",
    "    openai_api_type=\"azure\",\n",
    ")\n",
    "\n",
    "model(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French. I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "    ]\n",
    "\n",
    "agent_executor = initialize_agent(tools, model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for recent news or updates about the Italian male athletes for climbing at the Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"Italian male athletes climbing Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA select group of climbers ensured their participation in the 2024 Paris Olympics. Among them, Italy's Matteo Zurloni and Indonesia's Desak Made Rita Kusuma Dewi didn't just secure their Olympic berths; they also took home the world titles in their respective categories.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to refine my search to find a more comprehensive list of Italian male climbers for Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"List of Italian male climbers Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mItaly fielded a squad of five male gymnasts for Paris after advancing to the final round ... Paris 2024 qualification berths, and medals table - complete list\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThis information does not seem to be readily available, I should try contacting the Italian climbing federation for more information\n",
      "Action: Search\n",
      "Action Input: \"contact information for Italian climbing federation\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIFSC HEADQUARTERS: Corso Vinzaglio 12 10121, Torino, ITALY. Opening Hours: Monday - Friday 9:00 AM - 5:00 PM CEST. IFSC OFFICE:.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can reach out to the Italian climbing federation to ask for a list of their male athletes participating in the Paris 2024 Olympics\n",
      "Action: Contact\n",
      "Action Input: Email or phone call to the Italian climbing federation requesting information on the male athletes for Paris 2024 Olympics\u001b[0m\n",
      "Observation: Contact is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will refine my search further to see if any new information has been released about the Italian male climbers for the Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"Latest updates on Italian male climbers for Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAleksandra Miroslaw and Bassa Mawem have secured quota spots to next summer's Paris 2024 Olympic Games following respective wins at the IFSC ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information I have gathered, it seems that there is no comprehensive list of Italian male climbers for the Paris 2024 Olympics readily available. However, I do know that Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Olympics. \n",
      "Final Answer: Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Paris 2024 Olympics, but a comprehensive list of Italian male climbers for the Olympics is not readily available.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who are going to be the italian male athletes for climbing at the Paris 2024 Olympics?',\n",
       " 'output': 'Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Paris 2024 Olympics, but a comprehensive list of Italian male climbers for the Olympics is not readily available.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor('who are going to be the italian male athletes for climbing at the Paris 2024 Olympics?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
